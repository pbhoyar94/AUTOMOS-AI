#!/usr/bin/env python3
"""
AUTOMOS AI Demo Video Generator
Creates a working demonstration video with available tools
"""

import os
import sys
import cv2
import numpy as np
from datetime import datetime
from pathlib import Path

class AUTOMOSAIDemoVideoGenerator:
    """Generates demo video using OpenCV"""
    
    def __init__(self):
        """Initialize video generator"""
        self.output_dir = Path(__file__).parent / "output"
        self.output_dir.mkdir(exist_ok=True)
        
        # Video configuration
        self.width = 1920
        self.height = 1080
        self.fps = 30
        self.duration = 180  # 3 minutes
        
        # Colors
        self.blue = (0, 100, 200)
        self.white = (255, 255, 255)
        self.black = (0, 0, 0)
        self.green = (0, 255, 0)
        self.red = (0, 0, 255)
        self.yellow = (0, 255, 255)
        
        print("AUTOMOS AI Demo Video Generator Initialized")
    
    def create_title_screen(self, frame_count):
        """Create title screen frames"""
        frames = []
        
        for i in range(frame_count):
            frame = np.zeros((self.height, self.width, 3), dtype=np.uint8)
            frame[:] = self.blue
            
            # Animated title
            title_alpha = min(1.0, i / 30.0)
            title_size = int(3 * title_alpha)
            
            cv2.putText(frame, 'AUTOMOS AI', 
                       (self.width//2 - 300, self.height//2 - 50),
                       cv2.FONT_HERSHEY_SIMPLEX, title_size, self.white, 3)
            
            # Subtitle
            subtitle_alpha = min(1.0, max(0.0, (i - 30) / 30.0))
            if subtitle_alpha > 0:
                subtitle = "World's First Reasoning-Based Autonomous Driving Engine"
                cv2.putText(frame, subtitle,
                           (self.width//2 - 500, self.height//2 + 50),
                           cv2.FONT_HERSHEY_SIMPLEX, 1, 
                           tuple(int(c * subtitle_alpha) for c in self.white), 2)
            
            # Tagline
            tagline_alpha = min(1.0, max(0.0, (i - 60) / 30.0))
            if tagline_alpha > 0:
                tagline = "Complete Phase 1-3 Implementation"
                cv2.putText(frame, tagline,
                           (self.width//2 - 350, self.height//2 + 120),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8,
                           tuple(int(c * tagline_alpha) for c in self.white), 2)
            
            frames.append(frame)
        
        return frames
    
    def create_feature_showcase(self, frame_count):
        """Create feature showcase frames"""
        frames = []
        
        features = [
            {
                "title": "360Â° Multi-Camera Processing",
                "description": "Advanced vision backbone for comprehensive environmental perception",
                "icon": "ðŸ“¹"
            },
            {
                "title": "Safety-Critic System",
                "description": "<10ms response time with emergency override capability",
                "icon": "ðŸ›¡ï¸"
            },
            {
                "title": "Language-Conditioned Policy",
                "description": "Natural language control interface",
                "icon": "ðŸ—£ï¸"
            },
            {
                "title": "Real-Time World Model",
                "description": "HD-map-free navigation with predictive capabilities",
                "icon": "ðŸŒ"
            },
            {
                "title": "Edge Optimization",
                "description": "Model quantization for resource-constrained hardware",
                "icon": "âš¡"
            }
        ]
        
        frames_per_feature = frame_count // len(features)
        
        for feature_idx, feature in enumerate(features):
            for i in range(frames_per_feature):
                frame = np.zeros((self.height, self.width, 3), dtype=np.uint8)
                frame[:] = self.blue
                
                # Feature title
                cv2.putText(frame, feature["title"],
                           (100, 200),
                           cv2.FONT_HERSHEY_SIMPLEX, 2, self.white, 3)
                
                # Feature description
                words = feature["description"].split()
                lines = []
                current_line = []
                for word in words:
                    current_line.append(word)
                    if len(' '.join(current_line)) > 40:
                        lines.append(' '.join(current_line))
                        current_line = []
                if current_line:
                    lines.append(' '.join(current_line))
                
                for line_idx, line in enumerate(lines):
                    cv2.putText(frame, line,
                               (100, 300 + line_idx * 40),
                               cv2.FONT_HERSHEY_SIMPLEX, 1, self.white, 2)
                
                # Progress indicator
                progress = (i / frames_per_feature)
                bar_width = int(600 * progress)
                cv2.rectangle(frame, (100, 600), (700, 630), self.white, 2)
                cv2.rectangle(frame, (100, 600), (100 + bar_width, 630), self.green, -1)
                
                # Feature number
                cv2.putText(frame, f"Feature {feature_idx + 1}/{len(features)}",
                           (100, 700),
                           cv2.FONT_HERSHEY_SIMPLEX, 1, self.white, 2)
                
                # Animated elements
                angle = (i * 5) % 360
                center_x = self.width - 200
                center_y = self.height // 2
                radius = 80
                
                # Rotating circle
                cv2.circle(frame, (center_x, center_y), radius, self.white, 2)
                end_x = int(center_x + radius * np.cos(np.radians(angle)))
                end_y = int(center_y + radius * np.sin(np.radians(angle)))
                cv2.line(frame, (center_x, center_y), (end_x, end_y), self.yellow, 3)
                
                frames.append(frame)
        
        return frames
    
    def create_safety_demo(self, frame_count):
        """Create safety system demonstration"""
        frames = []
        
        for i in range(frame_count):
            frame = np.zeros((self.height, self.width, 3), dtype=np.uint8)
            frame[:] = self.blue
            
            # Title
            cv2.putText(frame, "Safety-Critic System",
                       (100, 100),
                       cv2.FONT_HERSHEY_SIMPLEX, 2, self.white, 3)
            
            # Response time visualization
            response_time = 5 + np.sin(i * 0.1) * 3  # Oscillating between 2-8ms
            response_text = f"Response Time: {response_time:.1f}ms"
            
            color = self.green if response_time < 10 else self.red
            cv2.putText(frame, response_text,
                       (100, 200),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)
            
            # Safety status
            status = "SAFE" if response_time < 10 else "WARNING"
            status_color = self.green if response_time < 10 else self.yellow
            
            cv2.putText(frame, f"Status: {status}",
                       (100, 300),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.5, status_color, 3)
            
            # Emergency scenario simulation
            if i > frame_count // 2:
                cv2.putText(frame, "EMERGENCY SCENARIO",
                           (100, 400),
                           cv2.FONT_HERSHEY_SIMPLEX, 1.5, self.red, 3)
                
                cv2.putText(frame, "Emergency Override Activated",
                           (100, 450),
                           cv2.FONT_HERSHEY_SIMPLEX, 1, self.red, 2)
                
                # Flashing effect
                if i % 10 < 5:
                    cv2.rectangle(frame, (50, 50), (self.width - 50, self.height - 50), 
                               self.red, 5)
            
            # Metrics panel
            cv2.rectangle(frame, (self.width - 400, 100), (self.width - 50, 400), 
                       self.white, 2)
            
            metrics = [
                f"Objects Detected: {np.random.randint(3, 8)}",
                f"Collision Risk: {np.random.uniform(0, 0.3):.2f}",
                f"System Health: {np.random.uniform(0.9, 1.0):.2f}",
                f"Uptime: {np.random.randint(24, 168)}h"
            ]
            
            for metric_idx, metric in enumerate(metrics):
                cv2.putText(frame, metric,
                           (self.width - 380, 140 + metric_idx * 60),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, self.white, 2)
            
            frames.append(frame)
        
        return frames
    
    def create_edge_deployment(self, frame_count):
        """Create edge deployment demonstration"""
        frames = []
        
        devices = [
            {"name": "Jetson Nano", "power": "10W", "performance": "22 FPS"},
            {"name": "Jetson Xavier", "power": "30W", "performance": "55 FPS"},
            {"name": "Raspberry Pi 4", "power": "8W", "performance": "12 FPS"},
            {"name": "Industrial PC", "power": "65W", "performance": "83 FPS"}
        ]
        
        frames_per_device = frame_count // len(devices)
        
        for device_idx, device in enumerate(devices):
            for i in range(frames_per_device):
                frame = np.zeros((self.height, self.width, 3), dtype=np.uint8)
                frame[:] = self.blue
                
                # Device name
                cv2.putText(frame, device["name"],
                           (100, 150),
                           cv2.FONT_HERSHEY_SIMPLEX, 2, self.white, 3)
                
                # Device specs
                specs = [
                    f"Power Consumption: {device['power']}",
                    f"Performance: {device['performance']}",
                    f"Optimization: INT8 Quantized",
                    f"Memory Usage: {np.random.randint(1, 4)}GB"
                ]
                
                for spec_idx, spec in enumerate(specs):
                    cv2.putText(frame, spec,
                               (100, 250 + spec_idx * 50),
                               cv2.FONT_HERSHEY_SIMPLEX, 1, self.white, 2)
                
                # Performance bars
                bar_width = int(device["performance"] * 5)
                cv2.rectangle(frame, (100, 500), (700, 530), self.white, 2)
                cv2.rectangle(frame, (100, 500), (100 + bar_width, 530), self.green, -1)
                
                # Device visualization
                center_x = self.width - 200
                center_y = self.height // 2
                
                # Device box
                cv2.rectangle(frame, (center_x - 60, center_y - 40), 
                           (center_x + 60, center_y + 40), self.white, 2)
                
                # Animated status light
                if i % 20 < 10:
                    cv2.circle(frame, (center_x, center_y - 80), 10, self.green, -1)
                else:
                    cv2.circle(frame, (center_x, center_y - 80), 10, self.yellow, -1)
                
                frames.append(frame)
        
        return frames
    
    def create_call_to_action(self, frame_count):
        """Create call to action frames"""
        frames = []
        
        for i in range(frame_count):
            frame = np.zeros((self.height, self.width, 3), dtype=np.uint8)
            frame[:] = self.blue
            
            # Main message
            alpha = min(1.0, i / 30.0)
            
            cv2.putText(frame, "AUTOMOS AI",
                       (self.width//2 - 250, self.height//2 - 100),
                       cv2.FONT_HERSHEY_SIMPLEX, 3, 
                       tuple(int(c * alpha) for c in self.white), 3)
            
            cv2.putText(frame, "The Future of Autonomous Driving",
                       (self.width//2 - 400, self.height//2),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.5,
                       tuple(int(c * alpha) for c in self.white), 2)
            
            # Contact information
            contact_alpha = min(1.0, max(0.0, (i - 60) / 30.0))
            if contact_alpha > 0:
                contact_info = [
                    "ðŸ“§ contact@automos-ai.com",
                    "ðŸŒ www.automos-ai.com",
                    "ðŸ“ž +1-800-AUTOMOS-AI"
                ]
                
                for info_idx, info in enumerate(contact_info):
                    cv2.putText(frame, info,
                               (self.width//2 - 200, self.height//2 + 100 + info_idx * 50),
                               cv2.FONT_HERSHEY_SIMPLEX, 1,
                               tuple(int(c * contact_alpha) for c in self.white), 2)
            
            # Final branding
            if i > frame_count - 30:
                fade_alpha = (frame_count - i) / 30.0
                cv2.putText(frame, "Ready for Deployment Today",
                           (self.width//2 - 250, self.height - 100),
                           cv2.FONT_HERSHEY_SIMPLEX, 1.5,
                           tuple(int(c * fade_alpha) for c in self.green), 2)
            
            frames.append(frame)
        
        return frames
    
    def generate_demo_video(self):
        """Generate complete demo video"""
        
        print("ðŸŽ¬ Generating AUTOMOS AI Demo Video")
        print("=" * 50)
        
        # Calculate frame counts for each section
        total_frames = self.duration * self.fps
        
        sections = [
            ("title", 30 * self.fps, self.create_title_screen),
            ("features", 60 * self.fps, self.create_feature_showcase),
            ("safety", 45 * self.fps, self.create_safety_demo),
            ("deployment", 45 * self.fps, self.create_edge_deployment),
            ("cta", 30 * self.fps, self.create_call_to_action)
        ]
        
        all_frames = []
        
        # Generate frames for each section
        for section_name, frame_count, generator in sections:
            print(f"ðŸ“¹ Creating {section_name} section ({frame_count} frames)...")
            frames = generator(frame_count)
            all_frames.extend(frames)
        
        # Create video writer
        output_path = self.output_dir / "automos_ai_demo_video.mp4"
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(str(output_path), fourcc, self.fps, 
                           (self.width, self.height))
        
        # Write frames
        print(f"ðŸ’¾ Writing {len(all_frames)} frames to video...")
        for i, frame in enumerate(all_frames):
            out.write(frame)
            
            if i % 100 == 0:
                print(f"   Processed {i}/{len(all_frames)} frames")
        
        # Release video writer
        out.release()
        
        print(f"âœ… Demo video created: {output_path}")
        print(f"ðŸ“Š Video specs: {self.width}x{self.height}, {self.fps} FPS, {len(all_frames)//self.fps}s")
        
        return output_path
    
    def create_short_demo(self):
        """Create 30-second short demo"""
        
        print("ðŸŽ¬ Creating 30-second demo reel...")
        
        short_duration = 30
        short_frames = short_duration * self.fps
        
        # Quick feature showcase
        frames = []
        
        for i in range(short_frames):
            frame = np.zeros((self.height, self.width, 3), dtype=np.uint8)
            frame[:] = self.blue
            
            # Rotating features
            features = [
                "360Â° Multi-Camera",
                "Safety-Critic System", 
                "Language Control",
                "Edge Optimization"
            ]
            
            feature_idx = (i // (short_frames // len(features))) % len(features)
            
            cv2.putText(frame, "AUTOMOS AI",
                       (self.width//2 - 200, 200),
                       cv2.FONT_HERSHEY_SIMPLEX, 2, self.white, 3)
            
            cv2.putText(frame, features[feature_idx],
                       (self.width//2 - 250, 400),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.5, self.yellow, 3)
            
            # Progress indicator
            progress = i / short_frames
            bar_width = int(600 * progress)
            cv2.rectangle(frame, (100, 700), (700, 730), self.white, 2)
            cv2.rectangle(frame, (100, 700), (100 + bar_width, 730), self.green, -1)
            
            frames.append(frame)
        
        # Write short video
        output_path = self.output_dir / "automos_ai_short_demo.mp4"
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(str(output_path), fourcc, self.fps, 
                           (self.width, self.height))
        
        for frame in frames:
            out.write(frame)
        
        out.release()
        
        print(f"âœ… Short demo created: {output_path}")
        return output_path

def main():
    """Main function"""
    
    generator = AUTOMOSAIDemoVideoGenerator()
    
    print("ðŸŽ¬ AUTOMOS AI Demo Video Generator")
    print("Choose video type:")
    print("1. Full Demo Video (3 minutes)")
    print("2. Short Demo Reel (30 seconds)")
    print("3. Both videos")
    
    try:
        choice = input("Enter choice (1-3): ").strip()
        
        if choice == "1":
            generator.generate_demo_video()
        elif choice == "2":
            generator.create_short_demo()
        elif choice == "3":
            generator.generate_demo_video()
            generator.create_short_demo()
        else:
            print("Invalid choice")
            
    except KeyboardInterrupt:
        print("\nVideo generation stopped")
    except Exception as e:
        print(f"Error: {e}")

if __name__ == "__main__":
    main()
